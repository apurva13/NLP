{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b700dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf31f2f8",
   "metadata": {},
   "source": [
    "### Reading and Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c90d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = sys.argv[1]\n",
    "file2 = sys.argv[2]\n",
    "file3= sys.argv[3]\n",
    "file4= sys.argv[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c3e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading the train, dev and test data\n",
    "train_data=[]\n",
    "dev_data=[]\n",
    "test_data=[]\n",
    "filePath=file1\n",
    "        \n",
    "with open(filePath, \"r\") as file:\n",
    "    for x in file:\n",
    "        x=x.rstrip()\n",
    "        train_data.append(x.split(\" \"))\n",
    "        \n",
    "with open(file2, \"r\") as file:\n",
    "    for x in file:\n",
    "        x=x.rstrip()\n",
    "        dev_data.append(x.split(\" \"))\n",
    "\n",
    "with open(file3, \"r\") as file:\n",
    "    for x in file:\n",
    "        x=x.rstrip()\n",
    "        test_data.append(x.split(\" \"))\n",
    "        \n",
    "train_words=list()\n",
    "temp=[]\n",
    "for i in train_data:\n",
    "    if len(i)<2:\n",
    "        train_words.append(temp)\n",
    "        temp=[]\n",
    "    else:\n",
    "        temp.append(i[1])\n",
    "        \n",
    "t_words=set()\n",
    "for i in train_data:\n",
    "    if len(i)>1:\n",
    "        t_words.add(i[1])\n",
    "        \n",
    "t_tags=set()\n",
    "for i in train_data:\n",
    "    if len(i)>1:\n",
    "        t_tags.add(i[2])\n",
    "c=2      \n",
    "train_word_idx={}\n",
    "for i in t_words:\n",
    "    train_word_idx[i]=c\n",
    "    c+=1\n",
    "    \n",
    "train_word_idx['<PAD>'] = 0\n",
    "train_word_idx['<UNK>'] = 1  \n",
    "\n",
    "\n",
    "train_ner_tag=list()\n",
    "temp=[]\n",
    "for i in train_data:\n",
    "    if len(i)<2:\n",
    "        train_ner_tag.append(temp)\n",
    "        temp=[]\n",
    "    else:\n",
    "        temp.append(i[2])\n",
    "\n",
    "        \n",
    "c=1      \n",
    "train_label_idx={}\n",
    "for i in t_tags:\n",
    "    train_label_idx[i]=c\n",
    "    c+=1\n",
    "    \n",
    "train_label_idx['<PAD>'] = 0\n",
    "\n",
    "\n",
    "train_sentences=[]\n",
    "train_tags=[]\n",
    "\n",
    "with open(file1, 'r', encoding='utf-8') as f:\n",
    "    words = []\n",
    "    ner_tags = []\n",
    "    for line in f:\n",
    "        if line == '\\n':\n",
    "            train_sentences.append(words)\n",
    "            train_tags.append(ner_tags)\n",
    "            words = []\n",
    "            ner_tags = []\n",
    "        else:\n",
    "            items = line.strip().split()\n",
    "            word = items[1]\n",
    "            ner_tag = items[2]\n",
    "            words.append(word)\n",
    "            ner_tags.append(ner_tag)\n",
    "            \n",
    "\n",
    "dev_words_tag_list=list()\n",
    "temp=[]\n",
    "for i in dev_data:\n",
    "    if len(i)<2:\n",
    "        dev_words_tag_list.append(temp)\n",
    "        temp=[]\n",
    "    else:\n",
    "        temp.append((i[0],i[1],i[2]))\n",
    "        \n",
    "dev_sentences=[]\n",
    "dev_tags=[]\n",
    "\n",
    "with open(file2, 'r', encoding='utf-8') as f:\n",
    "    words = []\n",
    "    ner_tags = []\n",
    "    for line in f:\n",
    "        if line == '\\n':\n",
    "            dev_sentences.append(words)\n",
    "            dev_tags.append(ner_tags)\n",
    "            words = []\n",
    "            ner_tags = []\n",
    "        else:\n",
    "            items = line.strip().split()\n",
    "            word = items[1]\n",
    "            ner_tag = items[2]\n",
    "            words.append(word)\n",
    "            ner_tags.append(ner_tag)\n",
    "        \n",
    "        \n",
    "test_word_tag_list=[]\n",
    "for x in test_data:\n",
    "    if len(x)>1:\n",
    "        test_word_tag_list.append((x[0],x[1]))\n",
    "        \n",
    "        \n",
    "test_sentences=[]\n",
    "with open(file3, 'r', encoding='utf-8') as f:\n",
    "    words = []\n",
    "    ner_tags = []\n",
    "    for line in f:\n",
    "        if line == '\\n':\n",
    "            test_sentences.append(words)\n",
    "            words = []\n",
    "        else:\n",
    "            items = line.strip().split()\n",
    "            word = items[1]\n",
    "            words.append(word)\n",
    "        \n",
    "test_sentence_tag_list=[]\n",
    "check=0\n",
    "tstl_test=[]\n",
    "\n",
    "for x in test_data:\n",
    "    if len(x)>1:\n",
    "            if x[0]=='1':\n",
    "                check+=1\n",
    "                if check == 1:\n",
    "                    tstl_test=[]\n",
    "                    tstl_test.append((x[0],x[1]))\n",
    "                elif check==3684:\n",
    "                    test_sentence_tag_list.append(tstl_test)\n",
    "                    tstl_test=[]\n",
    "                    tstl_test.append((x[0],x[1]) )\n",
    "                    test_sentence_tag_list.append(tstl_test)\n",
    "                    break\n",
    "                else: \n",
    "                    test_sentence_tag_list.append(tstl_test)\n",
    "                    tstl_test=[]\n",
    "                    tstl_test.append((x[0],x[1]))  \n",
    "            else:\n",
    "                tstl_test.append((x[0],x[1]))\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec0faac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3684"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sentence_tag_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbb5f9a",
   "metadata": {},
   "source": [
    "### Defining Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c9a9270",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "lstm_hidden_dim = 256\n",
    "lstm_layers = 1\n",
    "lstm_dropout = 0.33\n",
    "linear_output_dim = 128\n",
    "batch_size = 16\n",
    "learning_rate = 0.9\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76032c36",
   "metadata": {},
   "source": [
    "### Defining the dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab696d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class NERDataset(data.Dataset):\n",
    "    def __init__(self, sentences, tags,train_word_idx,train_label_idx,max_len):\n",
    "        self.sentences = sentences\n",
    "        self.tags = tags\n",
    "        self.train_word_idx=train_word_idx\n",
    "        self.train_label_idx=train_label_idx\n",
    "        self.max_len=max_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence=self.sentences[index]\n",
    "        tags= self.tags[index]\n",
    "        x = [self.train_word_idx.get(word, 1) for word in self.sentences[index]]\n",
    "        y = [self.train_label_idx[tag] for tag in tags]\n",
    "        x = x + [0] * (self.max_len - len(x))  # Pad the sequence with zeros\n",
    "        y = y + [0] * (self.max_len - len(y))  # Pad the sequence with zeros\n",
    "        return torch.LongTensor(x), torch.LongTensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "\n",
    "# Define the train dataset and data loader\n",
    "train_dataset = NERDataset(train_sentences, train_tags,train_word_idx,train_label_idx,max_len=113)\n",
    "dev_dataset = NERDataset(dev_sentences, dev_tags,train_word_idx,train_label_idx,max_len=109)\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = data.DataLoader(dev_dataset, batch_size=batch_size )\n",
    "# test_dataset = NERDataset()\n",
    "\n",
    "# Define the number of words and classes\n",
    "num_words = len(train_dataset.train_word_idx) + 1\n",
    "num_classes = len(train_dataset.train_label_idx) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c578a4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class NERDataset_test(data.Dataset):\n",
    "    def __init__(self, sentences,train_word_idx,max_len):\n",
    "        self.sentences = sentences\n",
    "        self.train_word_idx=train_word_idx\n",
    "        self.max_len=max_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence=self.sentences[index]\n",
    "        x = [self.train_word_idx.get(word, 1) for word in self.sentences[index]]\n",
    "        x = x + [0] * (self.max_len - len(x))  # Pad the sequence with zeros\n",
    "        return torch.LongTensor(x)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "\n",
    "# Define the train dataset and data loader\n",
    "test_dataset = NERDataset_test(test_sentences,train_word_idx,max_len=124)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Define the number of words and classes\n",
    "num_words = len(train_dataset.train_word_idx) + 1\n",
    "num_classes = len(train_dataset.train_label_idx) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462e2732",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d25d3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14 µs, sys: 0 ns, total: 14 µs\n",
      "Wall time: 16.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define the model architecture\n",
    "class BLSTM(nn.Module):\n",
    "    def __init__(self, embedding_dim, lstm_hidden_dim, lstm_layers, lstm_dropout, linear_output_dim):\n",
    "        super(BLSTM, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm_hidden_dim = lstm_hidden_dim\n",
    "        self.lstm_layers = lstm_layers\n",
    "        self.lstm_dropout = lstm_dropout\n",
    "        self.linear_output_dim = linear_output_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_words, embedding_dim=self.embedding_dim)\n",
    "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.lstm_hidden_dim, num_layers=self.lstm_layers, dropout=self.lstm_dropout, bidirectional=True)\n",
    "        self.linear = nn.Linear(self.lstm_hidden_dim*2, self.linear_output_dim)\n",
    "        self.activation = nn.ELU()\n",
    "        self.classifier = nn.Linear(self.linear_output_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d968253",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_label={}\n",
    "for key,val in train_label_idx.items():\n",
    "    idx_to_label[val]=key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02b4100f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_idx=train_label_idx['<PAD>']\n",
    "pad_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4670111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load(file4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9339a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predicted_labels = []\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, targets) in enumerate(dev_loader):\n",
    "        outputs = model(inputs)\n",
    "        predicted_labels.extend(torch.argmax(outputs, axis=-1).cpu().numpy())\n",
    "\n",
    "with open('dev_predicted.txt', 'w') as pred:\n",
    "    xP=[]\n",
    "    for pred_tags in predicted_labels:\n",
    "        t=[]\n",
    "        for i in pred_tags:\n",
    "            t.append(idx_to_label[i])\n",
    "\n",
    "        xP.append(t)\n",
    "    for inp in xP:\n",
    "        pred.write(' '.join(inp)+'\\n')\n",
    "\n",
    "model.eval()\n",
    "predicted_test_labels = []\n",
    "with torch.no_grad():\n",
    "for i, inputs in enumerate(test_loader):\n",
    "    outputs = model(inputs)\n",
    "    predicted_test_labels.extend(torch.argmax(outputs, axis=-1).cpu().numpy())\n",
    "\n",
    "with open('test_predicted.txt', 'w') as pred:\n",
    "    xP=[]\n",
    "    for pred_tags in predicted_test_labels:\n",
    "        t=[]\n",
    "        for i in pred_tags:\n",
    "            t.append(idx_to_label[i])\n",
    "\n",
    "        xP.append(t)\n",
    "    for inp in xP:\n",
    "        pred.write(' '.join(inp)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a33e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=[]\n",
    "with open(\"dev_predicted.txt\", \"r\") as f:\n",
    "    for x in f:\n",
    "        pred.append(x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec351af",
   "metadata": {},
   "outputs": [],
   "source": [
    "leng=[len(i) for i in dev_words_tag_list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e55ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ik=0\n",
    "tg=[]\n",
    "for sent in pred:\n",
    "    th=[]\n",
    "    lenk=0\n",
    "    for jk in sent:\n",
    "        if lenk<leng[ik]:\n",
    "            th.append(jk)\n",
    "            lenk=lenk+1\n",
    "    tg.append(th)\n",
    "    ik=ik+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d667a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = {}\n",
    "idx = 0\n",
    "for i in range(len(dev_words_tag_list)):\n",
    "    for j in range(len(dev_words_tag_list[i])):\n",
    "        final_output[idx] = (dev_words_tag_list[i][j][0], dev_words_tag_list[i][j][1],dev_words_tag_list[i][j][2], tg[i][j])\n",
    "        idx += 1\n",
    "    \n",
    "print(final_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b5c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "check=0\n",
    "with open(\"dev1.out\", 'w') as f: \n",
    "    for key,i in final_output.items() : \n",
    "        if i[0] == '1' and check!=0:\n",
    "            f.write('\\n')\n",
    "            f.write('%s %s %s\\n' % (i[0], i[1],i[3]))\n",
    "        else:\n",
    "            f.write('%s %s %s\\n' % (i[0], i[1],i[3]))\n",
    "            check=check+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f43ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test=[]\n",
    "with open(\"test_predicted.txt\", \"r\") as f:\n",
    "    for x in f:\n",
    "        pred_test.append(x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeca0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "leng_test=[len(i) for i in test_sentence_tag_list ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce678a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "new=[]\n",
    "for sent in pred_test:\n",
    "    temp=[]\n",
    "    lenk=0\n",
    "    for jk in sent:\n",
    "        if lenk<leng_test[c]:\n",
    "            temp.append(jk)\n",
    "            lenk=lenk+1\n",
    "    new.append(temp)\n",
    "    c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c69393",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_word_tag_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0fa4fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "final_output_test = {}\n",
    "idx_test = 0\n",
    "for i in range(len(test_sentence_tag_list)-1):\n",
    "    for j in range(len(test_sentence_tag_list[i])):\n",
    "        final_output_test[idx_test] = (test_sentence_tag_list[i][j][0], test_sentence_tag_list[i][j][1], new[i][j])\n",
    "        idx_test += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cb8def",
   "metadata": {},
   "outputs": [],
   "source": [
    "new[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb0b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "check=0\n",
    "with open(\"test1.out\", 'w') as f: \n",
    "    for key,i in final_output_test.items() : \n",
    "        if i[0] == '1' and check!=0:\n",
    "            f.write('\\n')\n",
    "            f.write('%s %s %s\\n' % (i[0], i[1],i[2]))\n",
    "        else:\n",
    "            f.write('%s %s %s\\n' % (i[0], i[1],i[2]))\n",
    "            check=check+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c3c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
